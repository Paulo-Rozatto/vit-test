{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from vit import PatchEmbed, MyViTBlock, get_positional_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViT(nn.Module):\n",
    "    def __init__(self, chw=(1, 28, 28), n_patches=7, hidden_d=16, n_heads=2, n_blocks=2, out_d=2):\n",
    "        super(ViT, self).__init__()\n",
    "\n",
    "        self.chw = chw\n",
    "        self.n_patches = n_patches\n",
    "        self.hidden_d = hidden_d\n",
    "\n",
    "        assert chw[1] % n_patches == 0, \"Input shape not entirely divisible by number of patches\"\n",
    "        assert chw[2] % n_patches == 0, \"Input shape not entirely divisible by number of patches\"\n",
    "        self.patch_size = (chw[1] // n_patches, chw[2] // n_patches)\n",
    "\n",
    "        # Patcher and mapper\n",
    "        self.patcher = PatchEmbed()\n",
    "\n",
    "        # Learnable classification token\n",
    "        self.class_token = nn.Parameter(torch.rand(1, self.hidden_d))\n",
    "\n",
    "        #  Positional embedding\n",
    "        self.register_buffer('pos_embed', get_positional_embeddings(\n",
    "            n_patches ** 2 + 1, hidden_d), persistent=False)\n",
    "\n",
    "        # Attention blocks\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [MyViTBlock(hidden_d, n_heads) for _ in range(n_blocks)])\n",
    "\n",
    "        # MLP classification\n",
    "        # self.mlp = nn.Sequential(\n",
    "        #     nn.Linear(self.hidden_d, out_d),\n",
    "        #     nn.Softmax(dim=-1)\n",
    "        # )\n",
    "\n",
    "    def forward(self, images):\n",
    "        tokens = self.patcher(images).flatten(1, 2)\n",
    "\n",
    "        tokens = torch.cat((self.class_token.expand(\n",
    "            len(tokens), 1, -1), tokens), dim=1)\n",
    "\n",
    "        # Adding positional embedding\n",
    "        pos_embed = self.pos_embed.repeat(len(tokens), 1, 1)\n",
    "        out = tokens + pos_embed\n",
    "\n",
    "        for block in self.blocks:\n",
    "            out = block(out)\n",
    "\n",
    "        # out = self.mlp(out[:, 0])\n",
    "\n",
    "        return out[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Adapted from:\n",
    "    https://github.com/facebookresearch/segment-anything/blob/main/segment_anything/modeling/prompt_encoder.py\n",
    "    \"\"\"\n",
    "    def __init__(self, image_size:int = 28, num_pos_feats:int = 8) -> None:\n",
    "        super().__init__()\n",
    "        self.image_size = image_size\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"positional_encoding_gaussian_matrix\",\n",
    "            torch.randn((2, num_pos_feats)),\n",
    "        )\n",
    "    \n",
    "    def _pe_encoding(self, coords: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Positionally encode points that are normalized to [0,1].\"\"\"\n",
    "        # assuming coords are in [0, 1]^2 square and have d_1 x ... x d_n x 2 shape\n",
    "        coords = 2 * coords - 1\n",
    "        coords = coords @ self.positional_encoding_gaussian_matrix\n",
    "        coords = 2 * np.pi * coords\n",
    "        # outputs d_1 x ... x d_n x C shape\n",
    "        return torch.cat([torch.sin(coords), torch.cos(coords)], dim=-1)\n",
    "    \n",
    "    def forward(self, coords_input):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        points: batch points predictions in formart [B, W, H]\n",
    "        \"\"\"\n",
    "        coords = coords_input.clone()\n",
    "        coords[:, 0] = coords[:, 0] / self.image_size\n",
    "        coords[:, 1] = coords[:, 1] / self.image_size\n",
    "        t = self._pe_encoding(coords.to(torch.float))  # B x N\n",
    "        return t\n",
    "\n",
    "tokenizer = TokenEncoder()\n",
    "tokenizer(torch.Tensor([[0, 0], [1,2], [0,0]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, hidden_d:int = 16, n_heads:int = 2, n_blocks:int = 2, out_d:int = 2, image_size:int = 28) -> None:\n",
    "        super().__init__()\n",
    "        self.max = 30\n",
    "\n",
    "        self.enconder = ViT()\n",
    "        self.token_enconder = TokenEncoder()\n",
    "        self.image_size = image_size\n",
    "\n",
    "        # Attention blocks\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [MyViTBlock(hidden_d, n_heads) for _ in range(n_blocks)])\n",
    "        \n",
    "        self.pred = nn.Sequential(\n",
    "            nn.Linear(hidden_d, out_d),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.flag = nn.Sequential(\n",
    "            nn.Linear(hidden_d, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, image, input_token):\n",
    "        tokens = self.enconder(image)\n",
    "        # token = self.token_enconder(input_token)\n",
    "        \n",
    "        i = 0\n",
    "        stop = 0\n",
    "        points = []\n",
    "        while(i < self.max):\n",
    "            token = self.token_enconder(input_token)\n",
    "            tokens = torch.cat([token.unsqueeze(1), tokens.unsqueeze(1)], dim=1)\n",
    "\n",
    "            for block in self.blocks:\n",
    "                tokens = block(tokens)\n",
    "            \n",
    "            tokens = tokens[:, 1]\n",
    "            input_token = self.pred(tokens)\n",
    "            # stop = self.flag(tokens) > 0.5\n",
    "            points.append(input_token.unsqueeze(1) * self.image_size)\n",
    "            i += 1\n",
    "        return torch.cat(points, dim=1)\n",
    "\n",
    "\n",
    "# x = torch.randn(2, 1, 28, 28).to(\"cuda\")\n",
    "# z = torch.randn(2, 2).to(\"cuda\")\n",
    "# model = Net().to(\"cuda\")\n",
    "# model(x, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  cuda (Quadro M5000)\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 1/5 [01:01<04:04, 61.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 loss: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|████      | 2/5 [01:14<01:39, 33.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 loss: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|██████    | 3/5 [01:27<00:47, 23.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 loss: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|████████  | 4/5 [01:45<00:21, 21.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 loss: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5/5 [02:01<00:00, 24.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 loss: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Loading data\n",
    "    transform = ToTensor()\n",
    "\n",
    "    train_set = MNIST(root='./datasets', train=True,\n",
    "                      download=True, transform=transform)\n",
    "    test_set = MNIST(root='./datasets', train=False,\n",
    "                     download=False, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_set, shuffle=True, batch_size=128)\n",
    "    test_loader = DataLoader(test_set, shuffle=False, batch_size=128)\n",
    "\n",
    "    # Defining model and training options\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    device_name = torch.cuda.get_device_name(device) if torch.cuda.is_available() else \"cpu\"\n",
    "    print(\"Using device: \", device, f\"({device_name})\")\n",
    "\n",
    "    model = Net().to(device)\n",
    "    N_EPOCHS = 5\n",
    "    LR = 0.005\n",
    "\n",
    "    batch_images, batch_labels = next(iter(train_loader))\n",
    "    print(batch_images.shape, batch_labels.shape)\n",
    "\n",
    "    # Training loop\n",
    "    optimizer = Adam(model.parameters(), lr=LR)\n",
    "    criterion = CrossEntropyLoss()\n",
    "    for epoch in trange(N_EPOCHS, desc=\"Training\"):\n",
    "        train_loss = 0.0\n",
    "    \n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1} in training\", leave=False):\n",
    "            x, _ = batch\n",
    "\n",
    "            inputs = torch.zeros(128, 2)\n",
    "            preds = model(x.to(device), inputs.to(device))\n",
    "\n",
    "            anns = []\n",
    "            for i in range(len(x)):\n",
    "                img = x[i].numpy()[0] * 255\n",
    "                img = img.astype(np.uint8)\n",
    "\n",
    "                cnt, _ = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "                cnt = max(cnt, key=cv2.contourArea)\n",
    "                poly = cv2.approxPolyDP(cnt, 0.0054 * cv2.arcLength(cnt, True), True)\n",
    "                anns.append(torch.tensor(poly.reshape(1, -1, 2)))\n",
    "            \n",
    "            loss = 0.0\n",
    "            for i in range(128):\n",
    "                pred = preds[i]\n",
    "                ann = anns[i][0]\n",
    "\n",
    "                if len(pred) > len(ann):\n",
    "                    offset = len(pred) - len(ann)\n",
    "                    zeros = torch.zeros(offset, 2)\n",
    "                    ann = torch.cat([ann, zeros]).to(device)\n",
    "                else:\n",
    "                    pred = nn.functional.pad(input=pred, pad=(len(ann), 2), value=0)\n",
    "\n",
    "                loss += criterion(pred, ann)\n",
    "            \n",
    "            train_loss += loss.detach().cpu().item() / len(train_loader)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            print(f\"Epoch {epoch + 1}/{N_EPOCHS} loss: {train_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5ecb8ae170>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = batch_images[0].numpy()[0] * 255\n",
    "img = img.astype(np.uint8)\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  5]]\n",
      "[13  5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5ecb2f4550>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnt, _ = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "cnt = max(cnt, key=cv2.contourArea)\n",
    "\n",
    "poly = cv2.approxPolyDP(cnt, 0.00054 * cv2.arcLength(cnt, True), True)\n",
    "\n",
    "print(poly[0])\n",
    "\n",
    "print(poly.reshape(-1, 2)[0])\n",
    "\n",
    "out = np.zeros((28,28, 3))\n",
    "out[:,:, 1] = np.copy(img)\n",
    "# out = np.copy(img)\n",
    "# cv2.drawContours(out, poly, -1, 255, 3)\n",
    "cv2.polylines(out, [poly], True, 255)\n",
    "\n",
    "plt.imshow(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
