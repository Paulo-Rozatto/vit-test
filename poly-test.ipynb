{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QpmEEQ-pdSB6"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss, MSELoss\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "from torchvision.datasets.mnist import MNIST\n",
        "\n",
        "from tqdm import tqdm, trange\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qF9zIOImdSB-"
      },
      "outputs": [],
      "source": [
        "def get_positional_embeddings(sequence_length, d):\n",
        "    result = torch.ones(sequence_length, d)\n",
        "    for i in range(sequence_length):\n",
        "        for j in range(d):\n",
        "            result[i][j] = np.sin(\n",
        "                i / (10000 ** (j / d))) if j % 2 == 0 else np.cos(i / (10000 ** ((j - 1) / d)))\n",
        "    return result\n",
        "\n",
        "\n",
        "class PatchEmbed(nn.Module):\n",
        "    \"\"\"\n",
        "    Image to Patch Embedding.\n",
        "    https://github.com/facebookresearch/segment-anything/blob/6fdee8f2727f4506cfbbe553e23b895e27956588/segment_anything/modeling/image_encoder.py#L364\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        kernel_size=(4, 4),\n",
        "        stride=(4, 4),\n",
        "        padding=(0, 0),\n",
        "        in_chans: int = 1,\n",
        "        embed_dim: int = 16,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            kernel_size (Tuple): kernel size of the projection layer.\n",
        "            stride (Tuple): stride of the projection layer.\n",
        "            padding (Tuple): padding size of the projection layer.\n",
        "            in_chans (int): Number of input image channels.\n",
        "            embed_dim (int): Patch embedding dimension.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.proj = nn.Conv2d(\n",
        "            in_chans, embed_dim, kernel_size=kernel_size, stride=stride, padding=padding\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.proj(x)\n",
        "        # B C H W -> B H W C\n",
        "        x = x.permute(0, 2, 3, 1)\n",
        "        return x\n",
        "\n",
        "\n",
        "class MyMSA(nn.Module):\n",
        "    def __init__(self, d, n_heads=2):\n",
        "        super(MyMSA, self).__init__()\n",
        "        self.d = d\n",
        "        self.n_heads = n_heads\n",
        "\n",
        "        assert d % n_heads == 0, f\"Can't divide dimension {d} into {n_heads} heads\"\n",
        "\n",
        "        d_head = int(d / n_heads)\n",
        "        self.q_mappings = nn.ModuleList(\n",
        "            [nn.Linear(d_head, d_head) for _ in range(self.n_heads)])\n",
        "        self.k_mappings = nn.ModuleList(\n",
        "            [nn.Linear(d_head, d_head) for _ in range(self.n_heads)])\n",
        "        self.v_mappings = nn.ModuleList(\n",
        "            [nn.Linear(d_head, d_head) for _ in range(self.n_heads)])\n",
        "        self.d_head = d_head\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, sequences):\n",
        "        # Sequences has shape (N, seq_length, token_dim)\n",
        "        # We go into shape    (N, seq_length, n_heads, token_dim / n_heads)\n",
        "        # And come back to    (N, seq_length, item_dim)  (through concatenation)\n",
        "        result = []\n",
        "        for sequence in sequences:\n",
        "            seq_result = []\n",
        "            for head in range(self.n_heads):\n",
        "                q_mapping = self.q_mappings[head]\n",
        "                k_mapping = self.k_mappings[head]\n",
        "                v_mapping = self.v_mappings[head]\n",
        "\n",
        "                seq = sequence[:, head * self.d_head: (head + 1) * self.d_head]\n",
        "                q, k, v = q_mapping(seq), k_mapping(seq), v_mapping(seq)\n",
        "\n",
        "                attention = self.softmax(q @ k.T / (self.d_head ** 0.5))\n",
        "                seq_result.append(attention @ v)\n",
        "            result.append(torch.hstack(seq_result))\n",
        "        return torch.cat([torch.unsqueeze(r, dim=0) for r in result])\n",
        "\n",
        "\n",
        "class MyViTBlock(nn.Module):\n",
        "    def __init__(self, hidden_d, n_heads, mlp_ratio=4):\n",
        "        super(MyViTBlock, self).__init__()\n",
        "        self.hidden_d = hidden_d\n",
        "        self.n_heads = n_heads\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(hidden_d)\n",
        "        self.mhsa = MyMSA(hidden_d, n_heads)\n",
        "        self.norm2 = nn.LayerNorm(hidden_d)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_d, mlp_ratio * hidden_d),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(mlp_ratio * hidden_d, hidden_d)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = x + self.mhsa(self.norm1(x))\n",
        "        out = out + self.mlp(self.norm2(out))\n",
        "        return out\n",
        "\n",
        "class ViT(nn.Module):\n",
        "    def __init__(self, chw=(1, 28, 28), n_patches=7, hidden_d=16, n_heads=2, n_blocks=2, out_d=2):\n",
        "        super(ViT, self).__init__()\n",
        "\n",
        "        self.chw = chw\n",
        "        self.n_patches = n_patches\n",
        "        self.hidden_d = hidden_d\n",
        "\n",
        "        assert chw[1] % n_patches == 0, \"Input shape not entirely divisible by number of patches\"\n",
        "        assert chw[2] % n_patches == 0, \"Input shape not entirely divisible by number of patches\"\n",
        "        self.patch_size = (chw[1] // n_patches, chw[2] // n_patches)\n",
        "\n",
        "        # Patcher and mapper\n",
        "        self.patcher = PatchEmbed()\n",
        "        self.mapper = nn.Linear(16, hidden_d)\n",
        "\n",
        "        # Learnable classification token\n",
        "        self.class_token = nn.Parameter(torch.rand(1, self.hidden_d))\n",
        "\n",
        "        #  Positional embedding\n",
        "        self.register_buffer('pos_embed', get_positional_embeddings(\n",
        "            n_patches ** 2 + 1, hidden_d), persistent=False)\n",
        "\n",
        "        # Attention blocks\n",
        "        self.blocks = nn.ModuleList(\n",
        "            [MyViTBlock(hidden_d, n_heads) for _ in range(n_blocks)])\n",
        "\n",
        "        # MLP classification\n",
        "        # self.mlp = nn.Sequential(\n",
        "        #     nn.Linear(self.hidden_d, out_d),\n",
        "        #     nn.Softmax(dim=-1)\n",
        "        # )\n",
        "\n",
        "    def forward(self, images):\n",
        "        tokens = self.patcher(images).flatten(1, 2)\n",
        "        tokens = self.mapper(tokens)\n",
        "\n",
        "        tokens = torch.cat((self.class_token.expand(\n",
        "            len(tokens), 1, -1), tokens), dim=1)\n",
        "\n",
        "        # Adding positional embedding\n",
        "        pos_embed = self.pos_embed.repeat(len(tokens), 1, 1)\n",
        "        out = tokens + pos_embed\n",
        "\n",
        "        for block in self.blocks:\n",
        "            out = block(out)\n",
        "\n",
        "        # out = self.mlp(out[:, 0])\n",
        "\n",
        "        return out[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "a8iE2bBtdSCA"
      },
      "outputs": [],
      "source": [
        "class TokenEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Adapted from:\n",
        "    https://github.com/facebookresearch/segment-anything/blob/main/segment_anything/modeling/prompt_encoder.py\n",
        "    \"\"\"\n",
        "    def __init__(self, image_size:int = 28, num_pos_feats:int = 8) -> None:\n",
        "        super().__init__()\n",
        "        self.image_size = image_size\n",
        "\n",
        "        self.register_buffer(\n",
        "            \"positional_encoding_gaussian_matrix\",\n",
        "            torch.randn((2, num_pos_feats)),\n",
        "        )\n",
        "\n",
        "    def _pe_encoding(self, coords: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Positionally encode points that are normalized to [0,1].\"\"\"\n",
        "        # assuming coords are in [0, 1]^2 square and have d_1 x ... x d_n x 2 shape\n",
        "        coords = 2 * coords - 1\n",
        "        coords = coords @ self.positional_encoding_gaussian_matrix\n",
        "        coords = 2 * np.pi * coords\n",
        "        # outputs d_1 x ... x d_n x C shape\n",
        "        return torch.cat([torch.sin(coords), torch.cos(coords)], dim=-1)\n",
        "\n",
        "    def forward(self, coords_input):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "        points: batch points predictions in formart [B, W, H]\n",
        "        \"\"\"\n",
        "        coords = coords_input.clone()\n",
        "        coords[:, 0] = coords[:, 0] / self.image_size\n",
        "        coords[:, 1] = coords[:, 1] / self.image_size\n",
        "        t = self._pe_encoding(coords.to(torch.float))  # B x N\n",
        "        return t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jpGDibcSdSCB"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, hidden_d:int = 8, n_heads:int = 1, n_blocks:int = 1, out_d:int = 2, image_size:int = 28) -> None:\n",
        "        super().__init__()\n",
        "        self.max = 30\n",
        "\n",
        "        self.enconder = ViT(hidden_d=hidden_d, n_heads=n_heads)\n",
        "        self.token_enconder = TokenEncoder(num_pos_feats=4)\n",
        "        self.image_size = image_size\n",
        "\n",
        "        # Attention blocks\n",
        "        self.blocks = nn.ModuleList(\n",
        "            [MyViTBlock(hidden_d, n_heads) for _ in range(n_blocks)])\n",
        "\n",
        "        self.pred = nn.Sequential(\n",
        "            nn.Linear(hidden_d, out_d),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.flag = nn.Sequential(\n",
        "            nn.Linear(hidden_d, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, image, input_token, in_tokens=None):\n",
        "        token = self.token_enconder(input_token).unsqueeze(1)\n",
        "        embedding = self.enconder(image).unsqueeze(1)\n",
        "\n",
        "        tokens = torch.cat([token, embedding], dim=1)\n",
        "\n",
        "        if in_tokens is not None:\n",
        "          tokens = torch.cat([tokens, in_tokens], dim=1)\n",
        "\n",
        "        for block in self.blocks:\n",
        "          tokens = block(tokens)\n",
        "\n",
        "        point = self.pred(tokens)[:, 0]\n",
        "\n",
        "        return point, tokens\n",
        "\n",
        "        tokens = self.enconder(image)\n",
        "        # token = self.token_enconder(input_token)\n",
        "\n",
        "        i = 0\n",
        "        stop = 0\n",
        "        points = []\n",
        "        while(i < self.max):\n",
        "            token = self.token_enconder(input_token)\n",
        "            tokens = torch.cat([token.unsqueeze(1), tokens.unsqueeze(1)], dim=1)\n",
        "\n",
        "            for block in self.blocks:\n",
        "                tokens = block(tokens)\n",
        "\n",
        "            tokens = tokens[:, 1]\n",
        "            input_token = self.pred(tokens)\n",
        "            # stop = self.flag(tokens) > 0.5\n",
        "            points.append(input_token.unsqueeze(1) * self.image_size)\n",
        "            i += 1\n",
        "        return torch.cat(points, dim=1)\n",
        "\n",
        "\n",
        "# x = torch.randn(2, 1, 28, 28).to(\"cuda\")\n",
        "# z = torch.randn(2, 2).to(\"cuda\")\n",
        "# model = Net().to(\"cuda\")\n",
        "# out = model(x, z)\n",
        "# print(out.shape)\n",
        "# print(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bGDKQEXTQ6Yb"
      },
      "outputs": [],
      "source": [
        "SIZE = 28\n",
        "MAX=10\n",
        "\n",
        "def preprocess(img, toTensor):\n",
        "  cnt, _ = cv2.findContours(np.array(img), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "  cnt = max(cnt, key=cv2.contourArea)\n",
        "  poly = cv2.approxPolyDP(cnt, 0.025 * cv2.arcLength(cnt, True), True) / SIZE\n",
        "  poly = torch.tensor(poly.reshape(-1, 2), dtype=torch.float32)\n",
        "\n",
        "  if (len(poly) < MAX):\n",
        "    zeros = torch.zeros(MAX - len(poly), 2)\n",
        "    poly = torch.cat([poly, zeros])\n",
        "\n",
        "  poly[MAX - 1] = torch.tensor([0, 0], dtype=torch.float32)\n",
        "\n",
        "  return toTensor(img), poly[:MAX]\n",
        "\n",
        "# Loading data\n",
        "transform = ToTensor()\n",
        "train_set = MNIST(root='./datasets', train=True,\n",
        "                  download=True, transform=Lambda(lambda x: preprocess(x, transform)))\n",
        "test_set = MNIST(root='./datasets', train=False,\n",
        "                 download=True, transform=Lambda(lambda x: preprocess(x, transform)))\n",
        "train_loader = DataLoader(train_set, shuffle=True, batch_size=128)\n",
        "test_loader = DataLoader(test_set, shuffle=False, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHf7mWq_dSCC",
        "outputId": "1b6d532d-dbd6-4390-a1d5-697a75c7ffbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device:  cuda (Quadro M5000)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  20%|██        | 1/5 [45:03<3:00:14, 2703.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5 loss: 0.45\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  40%|████      | 2/5 [1:29:59<2:14:56, 2698.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/5 loss: 0.38\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  60%|██████    | 3/5 [2:14:53<1:29:53, 2696.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/5 loss: 0.35\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  80%|████████  | 4/5 [2:59:44<44:54, 2694.76s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/5 loss: 0.34\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 5/5 [3:44:37<00:00, 2695.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/5 loss: 0.33\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Defining model and training options\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    device_name = torch.cuda.get_device_name(device) if torch.cuda.is_available() else \"cpu\"\n",
        "    print(\"Using device: \", device, f\"({device_name})\")\n",
        "\n",
        "    model = Net().to(device)\n",
        "    N_EPOCHS = 5\n",
        "    LR = 0.005\n",
        "\n",
        "    # model.load_state_dict(torch.load(\"/content/train_1.pth\"))\n",
        "\n",
        "    batch_images, batch_labels = next(iter(train_loader))\n",
        "    # print(batch_images.shape, batch_labels.shape)\n",
        "\n",
        "    # Training loop\n",
        "    optimizer = Adam(model.parameters(), lr=LR)\n",
        "    criterion = MSELoss()\n",
        "    for epoch in trange(N_EPOCHS, desc=\"Training\"):\n",
        "        train_loss = 0.0\n",
        "\n",
        "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1} in training\", leave=False):\n",
        "            x, _ = batch\n",
        "            img, poly = x\n",
        "\n",
        "            if len(img) < 128:\n",
        "              continue\n",
        "\n",
        "            img = img.to(device)\n",
        "            poly = poly.to(device)\n",
        "            inputs = torch.zeros(128, 2).to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss = 0.0\n",
        "            tokens = None\n",
        "\n",
        "            for i in range(MAX):\n",
        "              preds, tokens = model(img, inputs, tokens)\n",
        "\n",
        "              # print(preds[0], poly[0, i])\n",
        "              loss += criterion(preds, poly[:, i, :])\n",
        "\n",
        "              inputs = preds\n",
        "\n",
        "            train_loss += loss.detach().cpu().item() / len(train_loader)\n",
        "            # print(f\"Step loss: {loss:.2f}\")\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{N_EPOCHS} loss: {train_loss:.2f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "sjSUIUxFk_ET"
      },
      "outputs": [],
      "source": [
        "# Test loop\n",
        "# with torch.no_grad():\n",
        "#   correct, total = torch.zeros(128, 1), 0\n",
        "#   test_loss = 0.0\n",
        "#   inputs = torch.zeros(128, 2).to(device)\n",
        "\n",
        "#   for batch in tqdm(test_loader, desc=\"Testing\"):\n",
        "#     # x, y = x.to(device), y.to(device)\n",
        "#     x, _ = batch\n",
        "#     img, poly = x\n",
        "\n",
        "#     if len(img) < 128:\n",
        "#         break\n",
        "\n",
        "#     tokens = None\n",
        "#     for i in range(10):\n",
        "#       pred, tokens = model(img, inputs, tokens)\n",
        "#       loss = criterion(pred, poly[:, i, :])\n",
        "#       test_loss += loss.detach().cpu().item() / len(test_loader)\n",
        "\n",
        "#     # correct += torch.sum(torch.argmax(pred, dim=0) == poly).detach().cpu().item()\n",
        "#     print(pred[0], poly[0, 0])\n",
        "#     correct = torch.cdist(pred, poly[:, 0, :], p=2)\n",
        "#     total += len(img)\n",
        "\n",
        "#   print(torch.sum(correct), total)\n",
        "#   print(f\"Test loss: {test_loss:.2f}\")\n",
        "#   print(f\"Test accuracy: {torch.sum(correct) / total:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8FtFmPgqQD_Y"
      },
      "outputs": [],
      "source": [
        "path = \"train_1.pth\"\n",
        "torch.save(model.state_dict(), path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "dDxY2ZwodSCD",
        "outputId": "9b1564e3-3353-4646-c0c5-7bf10a15d535"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd2bb05cdf0>"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "img = batch_images[0].numpy()[0][0] * 255\n",
        "img = img.astype(np.uint8)\n",
        "plt.imshow(img, cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "-vVwKjXXdSCE",
        "outputId": "81b81ad4-8ae4-4d5b-db49-4545476e12af"
      },
      "outputs": [],
      "source": [
        "cnt, _ = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "cnt = max(cnt, key=cv2.contourArea)\n",
        "\n",
        "poly = cv2.approxPolyDP(cnt, 0.025 * cv2.arcLength(cnt, True), True)\n",
        "\n",
        "out = np.zeros((28,28, 3))\n",
        "out[:,:, 1] = np.copy(img)\n",
        "\n",
        "cv2.polylines(out, [poly], True, (0, 0, 255))\n",
        "\n",
        "for p in poly:\n",
        "    cv2.circle(out, p[0], radius=0, color=255, thickness=-1)\n",
        "\n",
        "plt.imshow(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeepZS3mRFx-",
        "outputId": "fb80b6aa-4347-4d4e-e1e9-769568416cc0"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "  inputs = torch.zeros(1, 2).to(device)\n",
        "  image = batch_images[0][0].reshape(1, 1, 28, 28).to(device)\n",
        "\n",
        "  # print(batch_images[0][1].shape, image.shape)\n",
        "\n",
        "  poly = []\n",
        "  tokens = None\n",
        "  for i in range(MAX):\n",
        "    # print(tokens.shape)\n",
        "    point, tokens = model(image, inputs, tokens)\n",
        "    inputs = point\n",
        "\n",
        "    poly.append(point)\n",
        "    if point[0][0] == 0 and point[0][1] == 0:\n",
        "      break\n",
        "\n",
        "poly = torch.cat(poly)\n",
        "print(poly[:-1], poly[:].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "FWeLNWWFTNrw",
        "outputId": "c71e073f-7378-4f8d-a881-2c006055b268"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd2baf36e30>"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "np_poly = poly[:-1].unsqueeze(1).to('cpu').numpy() * SIZE\n",
        "np_poly = np_poly.astype(np.int32)\n",
        "\n",
        "np_out = np.zeros((28,28, 3))\n",
        "np_out[:,:, 1] = np.copy(img)\n",
        "\n",
        "cv2.polylines(np_out, [np_poly], True, (0, 0, 255))\n",
        "\n",
        "for p in np_poly:\n",
        "    cv2.circle(np_out, p[0], radius=0, color=255, thickness=-1)\n",
        "\n",
        "plt.imshow(np_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "PmaG16DHVmQs",
        "outputId": "86a2b1ec-ff3e-464d-e3bd-0d718aed3246"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x700 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig = plt.figure(figsize=(10, 7))\n",
        "\n",
        "fig.add_subplot(1, 2, 1)\n",
        "plt.imshow(out)\n",
        "plt.axis('off')\n",
        "plt.title(\"Ground Truth\")\n",
        "\n",
        "fig.add_subplot(1, 2, 2)\n",
        "\n",
        "plt.imshow(np_out)\n",
        "plt.axis('off')\n",
        "plt.title(\"Prediction\")\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
